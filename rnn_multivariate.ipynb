{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6729e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/ -> Timeseries classification\n",
    "#https://keras.io/examples/timeseries/eeg_signal_classification/\n",
    "#https://towardsdatascience.com/time-series-analysis-on-multivariate-data-in-tensorflow-2f0591088502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08d6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "#date = \"230324\"\n",
    "date = \"230517\"\n",
    "DATA_DIR = os.path.join(\"..\", date)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c4661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = 1\n",
    "post_op = True\n",
    "#filename = \"Run_1_attention.xlsx\"\n",
    "if date == \"230324\":\n",
    "    filename = \"Run_\" + str(run_num) +\"_attention.xlsx\"\n",
    "elif date == \"230517\":\n",
    "    if run_num == 1:\n",
    "        filename = \"20230517T074332Z.xlsx\"\n",
    "    elif run_num == 2:\n",
    "        filename = \"20230517T084019Z.xlsx\"\n",
    "    else:\n",
    "        filename = \"20230517T100316Z.xlsx\"\n",
    "\n",
    "output_filename = \"av_metrics_\" + date + \"_run\" + str(run_num) + \".csv\"\n",
    "\n",
    "full_filename = os.path.join(DATA_DIR, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aacc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Recording timestamp  Computer timestamp Sensor Recording start time  \\\n",
      "0                    0                   0    NaN         09:43:32.124   \n",
      "\n",
      "   Recording duration Recording Fixation filter name           Event  \\\n",
      "0             2815701         Tobii I-VT (Attention)  RecordingStart   \n",
      "\n",
      "   Pupil diameter left  Pupil diameter right  Pupil diameter filtered  \\\n",
      "0                  NaN                   NaN                      NaN   \n",
      "\n",
      "  Eye movement type  Gaze event duration  Eye movement type index  \n",
      "0          Fixation                   97                        1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(full_filename)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a678bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if date == \"230324\":\n",
    "    if run_num == 1:\n",
    "        filename = \"Wl1_Friedrik_230324_093826.csv\"\n",
    "    else:\n",
    "        filename = \"Wl2_Fredrik_230324_112649.csv\"\n",
    "elif date == \"230517\":\n",
    "    if run_num == 1:\n",
    "        filename = \"Exp1_Fredrick_230517_084542.csv\"\n",
    "    elif run_num == 2:\n",
    "        filename = \"Exp2_Fredrick2_230517_094640.csv\"\n",
    "    else:\n",
    "        filename = \"Exp3_Fredrick_230517_111130.csv\"\n",
    "\n",
    "full_filename = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "score_df = pd.read_csv(full_filename, sep=' ',index_col=False)\n",
    "#print(score_df.head(1))\n",
    "\n",
    "score_df['score'] = score_df['score'].replace([0], 10)\n",
    "\n",
    "all_scores = list(score_df['score'])\n",
    "if post_op:\n",
    "    all_scores_post_op = list(score_df['post_op_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aa5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_in_ms=0.000001\n",
    "timeIntervalDuration = 180 #sec\n",
    "\n",
    "def getTimeInterval(ms_num):\n",
    "\n",
    "    return math.ceil(ms_num*sec_in_ms/timeIntervalDuration)\n",
    "\n",
    "df = df.drop([0])\n",
    "#fill the null rows with the mean of respective columns\n",
    "df = df.fillna(df.mean())\n",
    "df['timeInterval'] = df.apply(lambda row: getTimeInterval(row['Computer timestamp']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8070fb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Recording timestamp  Computer timestamp       Sensor Recording start time  \\\n",
      "1                 7027                7027  Eye Tracker         09:43:32.124   \n",
      "2                27118               27118  Eye Tracker         09:43:32.124   \n",
      "3                47100               47100  Eye Tracker         09:43:32.124   \n",
      "4                67190               67190  Eye Tracker         09:43:32.124   \n",
      "5                87172               87172  Eye Tracker         09:43:32.124   \n",
      "\n",
      "   Recording duration Recording Fixation filter name Event  \\\n",
      "1             2815701         Tobii I-VT (Attention)   NaN   \n",
      "2             2815701         Tobii I-VT (Attention)   NaN   \n",
      "3             2815701         Tobii I-VT (Attention)   NaN   \n",
      "4             2815701         Tobii I-VT (Attention)   NaN   \n",
      "5             2815701         Tobii I-VT (Attention)   NaN   \n",
      "\n",
      "   Pupil diameter left  Pupil diameter right  Pupil diameter filtered  \\\n",
      "1                3.091                 3.131                    3.111   \n",
      "2                3.082                 3.131                    3.106   \n",
      "3                3.080                 3.097                    3.090   \n",
      "4                3.083                 3.099                    3.089   \n",
      "5                3.078                 3.094                    3.089   \n",
      "\n",
      "  Eye movement type  Gaze event duration  Eye movement type index  \\\n",
      "1          Fixation                   97                        1   \n",
      "2          Fixation                   97                        1   \n",
      "3          Fixation                   97                        1   \n",
      "4          Fixation                   97                        1   \n",
      "5          Fixation                   97                        1   \n",
      "\n",
      "   timeInterval  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "5             1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8890e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2815701240\n",
      "16\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[9024, 9020, 9019, 9020, 9020, 9019, 9026, 9020, 9020, 9012, 9020, 9020, 9019, 9020, 9020, 5798]\n",
      "5798\n",
      "[5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798, 5798]\n"
     ]
    }
   ],
   "source": [
    "last_timestamp = list(df['Computer timestamp'])[-1]\n",
    "print(last_timestamp)\n",
    "last_timeinterval = getTimeInterval(last_timestamp)\n",
    "print(last_timeinterval)\n",
    "\n",
    "diameters = []\n",
    "intervals = []\n",
    "num_of_values =[]\n",
    "\n",
    "for ti in range (1, last_timeinterval + 1):\n",
    "    ti_df = df[df['timeInterval']==ti]\n",
    "    ti_diams = ti_df['Pupil diameter filtered'].dropna().tolist()\n",
    "    diameters.append(ti_diams)\n",
    "    num_of_values.append(len(ti_diams))\n",
    "    intervals.append(ti)\n",
    "\n",
    "print(intervals)\n",
    "#print(diameters)\n",
    "print(num_of_values)\n",
    "min_num = min(num_of_values)\n",
    "print(min_num)\n",
    "\n",
    "new_num_of_values = []\n",
    "for i in range (0, last_timeinterval):\n",
    "    diameters[i] = diameters[i][-abs(min_num)::1]\n",
    "    new_num_of_values.append(len(diameters[i]))\n",
    "print(new_num_of_values)\n",
    "window_size = min_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8a0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(all_scores))\n",
    "\n",
    "intervals_num = len(intervals)\n",
    "print(intervals_num)\n",
    "if len(all_scores) > intervals_num:\n",
    "    scores = all_scores[1:intervals_num+1]\n",
    "    if post_op:\n",
    "        scores_post_op = all_scores_post_op[1:intervals_num+1]\n",
    "else:\n",
    "    scores = all_scores[1:]\n",
    "    if post_op:\n",
    "        scores_post_op = all_scores_post_op[1:]\n",
    "print(len(scores))\n",
    "\n",
    "number_of_points = len(scores)\n",
    "\n",
    "intervals = intervals[0:number_of_points]\n",
    "diameters = diameters[0:number_of_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483cc47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "series_list = [\n",
    "    scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in diameters\n",
    "]\n",
    "print(len(series_list))\n",
    "\n",
    "le = preprocessing.LabelEncoder()  # Generates a look-up table\n",
    "le.fit(scores)\n",
    "scores = le.transform(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015aadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting in the end\n",
    "diams_df = pd.DataFrame(list(zip(diameters, scores)), columns =['diameters', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e917d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(set(scores))\n",
    "unique, counts = np.unique(scores, return_counts=True)\n",
    "print(num_classes)\n",
    "print(type(num_classes))\n",
    "plt.bar(range(num_classes), counts)\n",
    "plt.title(\"Number of samples per class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b1b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "Length of x_train : 11\n",
      "Length of x_test : 3\n",
      "Length of y_train : 11\n",
      "Length of y_test : 3\n"
     ]
    }
   ],
   "source": [
    "print(len(series_list))\n",
    "print(len(scores))\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    series_list, scores, test_size=0.15, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Length of x_train : {len(x_train)}\\nLength of x_test : {len(x_test)}\\nLength of y_train : {len(y_train)}\\nLength of y_test : {len(y_test)}\"\n",
    ")\n",
    "\n",
    "x_train = np.asarray(x_train).astype(np.float32).reshape(-1, window_size, 1)\n",
    "y_train = np.asarray(y_train).astype(np.float32).reshape(-1, 1)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "x_test = np.asarray(x_test).astype(np.float32).reshape(-1, window_size, 1)\n",
    "y_test = np.asarray(y_test).astype(np.float32).reshape(-1, 1)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c37dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7634b4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.7857142857142857, 0: 0.8571428571428572, 2: 0.5714285714285714, 3: 0.7857142857142857}\n"
     ]
    }
   ],
   "source": [
    "vals_dict = {}\n",
    "for i in scores:\n",
    "    if i in vals_dict.keys():\n",
    "        vals_dict[i] += 1\n",
    "    else:\n",
    "        vals_dict[i] = 1\n",
    "total = sum(vals_dict.values())\n",
    "\n",
    "# Formula used - Naive method where\n",
    "# weight = 1 - (no. of samples present / total no. of samples)\n",
    "# So more the samples, lower the weight\n",
    "\n",
    "weight_dict = {k: (1 - (v / total)) for k, v in vals_dict.items()}\n",
    "print(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec774d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history: keras.callbacks.History):\n",
    "    total_plots = len(history.history)\n",
    "    cols = total_plots // 2\n",
    "\n",
    "    rows = total_plots // cols\n",
    "\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "\n",
    "    pos = range(1, total_plots + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (key, value) in enumerate(history.history.items()):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(range(len(value)), value)\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5786761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = keras.Input(shape=(window_size, 1))\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=32, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=64, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=128, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=256, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=512, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=1024, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        2048, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(\n",
    "        128, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e53ce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5798, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 2899, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2899, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1450, 64)          6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1450, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 725, 128)          41088     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 725, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 363, 256)          164096    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 363, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 182, 512)          918016    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 182, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 91, 1024)          3671040   \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 91, 1024)          4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 91, 1024)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93184)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              381685760 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397114948 (1.48 GB)\n",
      "Trainable params: 397110916 (1.48 GB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model = create_model()\n",
    "\n",
    "print(conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23b56766",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_top_k_categorical_accuracy\",\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=0.000001,\n",
    "    ),\n",
    "]\n",
    "\n",
    "optimizer = keras.optimizers.Adam(amsgrad=True, learning_rate=0.001)\n",
    "loss = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681880b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 24s 24s/step - loss: 45.0935 - top_k_categorical_accuracy: 0.7273 - auc: 0.3981 - precision: 0.1000 - recall: 0.0909 - val_loss: 43.5685 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.4074 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 4s 4s/step - loss: 62.6396 - top_k_categorical_accuracy: 0.9091 - auc: 0.6970 - precision: 0.5455 - recall: 0.5455 - val_loss: 42.7870 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.5556 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 4s 4s/step - loss: 57.1187 - top_k_categorical_accuracy: 0.9091 - auc: 0.5565 - precision: 0.3636 - recall: 0.3636 - val_loss: 42.3722 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.4815 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 31s 31s/step - loss: 44.4427 - top_k_categorical_accuracy: 0.9091 - auc: 0.8567 - precision: 0.6364 - recall: 0.6364 - val_loss: 42.4080 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3889 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 3s 3s/step - loss: 46.7988 - top_k_categorical_accuracy: 0.9091 - auc: 0.8595 - precision: 0.7273 - recall: 0.7273 - val_loss: 42.3863 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3519 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 42.1080 - top_k_categorical_accuracy: 1.0000 - auc: 0.9339 - precision: 0.8182 - recall: 0.8182 - val_loss: 42.4554 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3519 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 4.0000e-05\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 34s 34s/step - loss: 41.4003 - top_k_categorical_accuracy: 1.0000 - auc: 0.9394 - precision: 0.9091 - recall: 0.9091 - val_loss: 42.5298 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 4.0000e-05\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 20s 20s/step - loss: 40.3574 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 42.6607 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.0000e-06\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3458 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 42.8025 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3519 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.0000e-06\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3399 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 42.9603 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.6000e-06\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 20s 20s/step - loss: 40.3387 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 43.1239 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.2778 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.6000e-06\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3374 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 43.2940 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3371 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 43.4686 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 20s 20s/step - loss: 40.3361 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 43.6468 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.2963 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3350 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 43.8272 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.3704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 19s 19s/step - loss: 40.3341 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 44.0095 - val_top_k_categorical_accuracy: 0.6667 - val_auc: 0.2963 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 40.3333 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000"
     ]
    }
   ],
   "source": [
    "conv_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        keras.metrics.TopKCategoricalAccuracy(k=3),\n",
    "        keras.metrics.AUC(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "conv_model_history = conv_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=test_dataset,\n",
    "    class_weight=weight_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb00ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_metrics(conv_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917741b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auc, precision, recall = conv_model.evaluate(test_dataset)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Top 3 Categorical Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_evaluated_diameters_plots(model):\n",
    "    start_index = 0\n",
    "    end_index = number_of_points\n",
    "    data = diams_df.loc[start_index:end_index, \"diameters\"]\n",
    "    data_array = [scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in data]\n",
    "    data_array = [np.asarray(data_array).astype(np.float32).reshape(-1, window_size, 1)]\n",
    "    original_labels = diams_df.loc[start_index:end_index, \"score\"]\n",
    "    predicted_labels = np.argmax(model.predict(data_array, verbose=0), axis=1)\n",
    "    original_labels = [\n",
    "        le.inverse_transform(np.array(label).reshape(-1))[0]\n",
    "        for label in original_labels\n",
    "    ]\n",
    "    predicted_labels = [\n",
    "        le.inverse_transform(np.array(label).reshape(-1))[0]\n",
    "        for label in predicted_labels\n",
    "    ]\n",
    "    total_plots = number_of_points\n",
    "    cols = total_plots // 3\n",
    "    rows = total_plots // cols\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "    pos = range(1, total_plots + 1)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i, (plot_data, og_label, pred_label) in enumerate(\n",
    "        zip(data, original_labels, predicted_labels)\n",
    "    ):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(plot_data)\n",
    "        plt.title(f\"Actual Label : {og_label}\\nPredicted Label : {pred_label}\")\n",
    "        fig.subplots_adjust(hspace=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "view_evaluated_diameters_plots(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02137b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
